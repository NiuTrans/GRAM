<!-- <div align="center">
  <h1>A Generative Foundation Reward Model for Reward Generalization</h1>
  <p align="center" dir="auto">
  <a href="https://"> ã€Paperã€‘ ğŸ“ </a> | 
  <a href="https://"> ã€Modelsã€‘ ğŸ¤— </a> 
  </p>
</div> -->

# A Generative Foundation Reward Model (GRAM)

This repository contains the code and released models for our paper [GRAM: A Generative Foundation Reward Model for Reward Generalization ğŸ“](). We propose a more effective approach to reward model training by combining both labeled and unlabeled data. Our method introduces a generative reward model that first learns from a large corpus of unlabeled data and is then fine-tuned with supervised data. Please find all the released model checkpoints at [this link ğŸ¤—]().

<img src="./gram.png" width="1000px"></img>


## ğŸ†• Changelog



## ğŸ”— Quick Links
- [GRAM: A Generative Foundation Reward Model for Reward Generalization](#a-generative-foundation-reward-model-GRAM)
  <!-- - [Changelog](#-changelog)
  - [Tips for Running SimPO](#tips-for-running-simpo)
  - [Released Models](#released-models)
  - [Install Requirements](#install-requirements)
  - [Training scripts](#training-scripts)
  - [Evaluation](#evaluation)
  - [Bugs or Questions?](#bugs-or-questions)
  - [Citation](#citation) -->
